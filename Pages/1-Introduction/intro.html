<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RLH: Introduction</title>
    <link rel="stylesheet" href="styles.css">
    <script src="script.js" defer></script>
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;600&display=swap" rel="stylesheet">
    <!-- Font Awesome for icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>
<body>
    <header>
        <div class="logo">
            <img src="Pictures/logo.png" alt="Logo">
            <span>مقدمه</span>
        </div>
        <nav>
            <a href="https://the-rl-hub.github.io/">خانه</a>
            <a href="#">درباره ما</a>
            <a href="#"></a>
        </nav>
    </header>

    <main>
        <aside class="sidebar">
            <ul>
                <li><a href="#intro">مقدمه‌ای بر Reinforcement Learning</a></li>
                <li><a href="#trial-error">یادگیری از طریق آزمون و خطا</a></li>
                <li><a href="#rl-overview">Reinforcement Learning چیه؟</a></li>
                <li><a href="#rl-vs-supervised">RL و تفاوت با Supervised و Unsupervised Learning</a></li>
                <li><a href="#rl-examples">مثال‌هایی از RL در عمل</a></li>
            </ul>
        </aside>
    
        <section class="content">
            <h1 id="intro">مقدمه‌ای بر Reinforcement Learning</h1>
            <hr>
    
            <h2 id="trial-error">یادگیری از طریق آزمون و خطا: شهود اصلی در Reinforcement Learning</h2>
    
            <p>
                Reinforcement Learning یا RL رو می‌شه به‌عنوان نمونه‌ی کامل یادگیری از طریق انجام دادن در نظر گرفت. فرض کن یه بچه بخواد دوچرخه‌سواری یاد بگیره. اولش ممکنه تلوتلو بخوره، بیفته یا برای حفظ تعادل کلی تقلا کنه. اما با بارها و بارها تلاش کردن—آزمون و خطا—کم‌کم می‌فهمه چی جواب می‌ده و چی نمی‌ده. هر بار افتادن بهش یاد می‌ده که چطوری تعادلشو حفظ کنه و هر حرکت موفق هم همون کار درستو تو ذهنش تثبیت می‌کنه. این دقیقاً شبیه چیزی هست که تو RL اتفاق می‌افته: یادگیری از طریق آزمون و خطا.
            </p>
    
            <div class="box box-question">
                <strong>سؤال: فکر کن به یه چیزی که تازگیا یاد گرفتی، مثلاً آشپزی کردن یا نواختن یه ساز. به نظرت تو اولین تلاش موفق بودی یا با نتایج کارت تغییرش دادی؟ این موضوع چه شباهتی به چیزی داره که RL انجام می‌ده؟</strong> 
            </div>
            <p>
                ایده اصلی RL ساده اما خیلی قویه: ایجنتا با تعامل با محیطشون یاد می‌گیرن و با توجه به بازخورد (پاداش) که می‌گیرن، کاراشونو تنظیم می‌کنن. ایجنت گزینه‌های مختلفو بررسی می‌کنه، چیزایی که قبلاً امتحان نکرده رو تست می‌کنه و بین استفاده از چیزایی که می‌دونه خوب جواب می‌ده (بهره‌برداری) و امتحان کردن گزینه‌های جدید که شاید بهتر باشن (کاوش) یه تعادل برقرار می‌کنه.
            </p>

            <div class="box box-question">
                <strong>یه فکر جالب: فرض کن یه دستگاه اسلات داری که چندتا اهرم داره و هرکدومشون پاداشای متفاوت اما ناشناخته‌ای دارن. چطوری تصمیم می‌گیری کدوم اهرمو بکشی؟ به همون اهرمی که آخرین بار بهت جایزه داده بچسبی یا یه اهرم جدید امتحان کنی؟ این دقیقاً همون مفهوم معضل کاوش و بهره‌برداری تو RL هست.</strong> 
            </div>

            <p>
                تعادلی که به اسم exploration-exploitation trade-off شناخته می‌شه، یکی از چالشای اصلی تو RL به حساب میاد. مثلاً یه ربات که می‌خواد تو یه هزارتو راه پیدا کنه باید تصمیم بگیره که آیا از مسیری که می‌دونه به هدف می‌رسه استفاده کنه (بهره‌برداری) یا یه مسیر جدید امتحان کنه که شاید کوتاه‌تر باشه (کاوش). پیدا کردن این تعادل خیلی مهمه، چون اگه زیادی کاوش کنه وقتو تلف می‌کنه و اگه فقط بهره‌برداری کنه شاید تو رفتارای غیربهینه گیر کنه.
            </p>
            
            <div class="box box-question">
                <strong>سؤال چالشی: اگه رباتی که تو هزارتو کاوش می‌کنه برای انتخاب مسیر اشتباه جریمه بشه، این موضوع چطوری ممکنه استراتژیشو تغییر بده؟ اگه جای ربات بودی چیکار می‌کردی؟</strong> 
            </div>
    
            <hr>
    
            <h2 id="rl-overview">Reinforcement Learning چیه؟ یه مسئله، یه راه‌حل و یه حوزه تحقیقاتی</h2>
    
            <p>
                Reinforcement Learning از اون چیزاییه که خیلی انعطاف‌پذیره و می‌تونه تو سه نقش مختلف ظاهر بشه:
            </p>
    
            <ul>
                <li><strong>یه مسئله:</strong> تو هسته خودش، RL مسئله یادگیری هدفمند تو محیطای نامطمئن رو بررسی می‌کنه. مثلاً یه ربات چطوری باید تصمیم بگیره که چه کاری انجام بده تا هم باتریشو حفظ کنه و هم کارشو تموم کنه؟ یا یه برنامه شطرنج چطور باید حرکتای خودشو انتخاب کنه که برنده بشه؟</li>
                <li><strong>یه راه‌حل:</strong> RL شامل یه سری روشای حل مثل Q-learning، policy gradients یا deep reinforcement learning هست که برای حل این مسئله طراحی شدن. این روشا به ایجنت کمک می‌کنن که از بازخورد یاد بگیره و رفته‌رفته بهتر بشه.</li>
                <li><strong>یه حوزه تحقیقاتی:</strong> علاوه بر مسائل و راه‌حل‌ها، RL یه حوزه تحقیقاتی حسابی پر و پیمونه که ریاضیات، علوم کامپیوتر، علوم اعصاب و روانشناسی رو شامل می‌شه. این حوزه بررسی می‌کنه که ایجنت‌ها چطوری یاد می‌گیرن و چطوری می‌شه این یادگیریو کارآمدتر و قابل اعمال‌تر کرد.</li>
            </ul>
    
            <div class="box box-question">
                <strong>یه لحظه فکر کن:</strong> به نظرت تو کجای زندگی یا کارت می‌شه از چیزی شبیه "یادگیری از بازخورد" استفاده کرد؟ چطوری می‌تونی یه "سیستم پاداش" طراحی کنی که بهت کمک کنه بهتر یاد بگیری؟
            </div>

            <p>
                یه نکته خیلی مهم تو RL، تمایز بین مسائل و روشای حل هست. مثلاً، معضل کاوش و بهره‌برداری یه مسئله مشترک تو خیلی از کارای RL هست، اما می‌شه با روشای مختلفی مثل استراتژی‌های ε-greedy یا Thompson sampling حلش کرد. اگه این تمایزو قاطی کنیم، خیلی چیزا اشتباه می‌شه، چون ممکنه یه مسئله بسته به شرایط راه‌حلای کاملاً متفاوتی بخواد.
            </p>

            <div class="box box-question">
                <strong>کاوش بیشتر:</strong> استراتژی‌های ε-greedy رو یه نگاهی بنداز یا ببین "کاوش" تو بازی ویدیویی موردعلاقت چطوری انجام می‌شه. طراحای بازی چطوری این تعادلو برقرار می‌کنن؟
            </div>


    
            <hr>
    
            <h2 id="rl-vs-supervised">RL چه فرقی با Supervised و Unsupervised Learning داره؟</h2>
    
            <p>
                Reinforcement Learning معمولاً با بقیه پارادایم‌های یادگیری ماشین مثل <strong>supervised</strong> و <strong>unsupervised learning</strong> مقایسه می‌شه، ولی از اساس یه چیز کاملاً متفاوتیه.
            </p>
            <ul>
                <li><strong>Supervised Learning: </strong>تو یادگیری تحت نظارت (supervised)، ایجنت از یه مجموعه داده برچسب‌دار که یه سرپرست آماده کرده، یاد می‌گیره. مثلاً یه سیستم تشخیص گربه و سگ با کلی عکس که به عنوان "گربه" یا "سگ" برچسب خوردن آموزش می‌بینه. هدف اینه که ایجنت از این نمونه‌ها تعمیم بده و عکسای جدیدو درست دسته‌بندی کنه.

                    <div class="box box-question">
                        <strong>یه سؤال باحال:</strong> اگه supervised شبیه یادگیری با یه معلم باشه، RL شبیه چیه؟ می‌شه گفت شبیه یادگیری از طریق کشف و تجربه است؟
                    </div>
                    ولی RL به داده‌های برچسب‌دار نیاز نداره. در عوض، مستقیماً از تعامل با محیط یاد می‌گیره. هیچ جواب مشخص و از پیش تعیین‌شده‌ای وجود نداره؛ ایجنت باید خودش کشفش کنه. مثلاً رباتی که یاد می‌گیره راه بره، دستورالعمل خاصی نمی‌گیره که چطوری پاهاشو حرکت بده—بلکه با امتحان کردن و دیدن نتیجه، خودش یاد می‌گیره.
                </li><br>
                <li><strong>Unsupervised Learning: </strong>تو یادگیری بدون نظارت (unsupervised)، هدف کشف الگوها یا ساختارهای پنهان تو داده‌هاست، مثل خوشه‌بندی مشتریا یا کاهش ابعاد داده‌ها. RL یه شباهتی به این روش داره چون به داده برچسب‌دار نیاز نداره، ولی تمرکزش بیشتر روی به حداکثر رسوندن سیگنال پاداش هست، نه کشف الگوها. مثلاً یه ایجنت RL که شطرنج بازی می‌کنه دنبال خوشه‌بندی حرکات شطرنج نیست—فقط می‌خواد بازیو ببره.
                    <div class="box box-question">
                        <strong>یه سؤال باحال:</strong> چرا فکر می‌کنی RL بیشتر شبیه به آزمون و خطاست تا یادگیری تحت نظارت یا بدون نظارت؟ RL چه مسائلیو بهتر می‌تونه حل کنه؟
                    </div>
                    به طور کلی، RL یه موقعیت منحصربه‌فرد داره و به‌عنوان یه پارادایم سوم تو یادگیری ماشین شناخته می‌شه. RL کاوش، تعامل و رفتار هدف‌محوری رو ترکیب می‌کنه که تو بقیه پارادایما نیست، و برای حل مسائلی که راهنمایی مستقیم توشون وجود نداره، خیلی قویه.
                </li>
            </ul>
    
            
    
            <hr>
    
            <h2 id="rl-examples">مثال‌هایی از RL در عمل</h2>
    
            <ul>
                <li><strong>ماشین‌های خودران:</strong>این ماشینا از RL استفاده می‌کنن تا تو جاده حرکت کنن، از موانع رد شن و تصمیم‌گیریای لحظه‌ای کنن. ایجنت (ماشین) با محیط (شرایط جاده و ترافیک) تعامل داره و یاد می‌گیره ایمنی و کارایی رو به حداکثر برسونه و تصادفاتو کم کنه.
                    <div class="box box-tip">
                        <strong>چالش:</strong> تصور کن یه سیستم RL برای ماشینای خودران طراحی می‌کنی. چطوری به ماشین پاداش می‌دی؟ فقط اجتناب از تصادف کافیه یا برای مصرف انرژی کمتر یا راحتی مسافرا هم پاداش می‌ذاری؟
                    </div>
                </li>
                <li><strong>کنترل رباتیک:</strong> رباتایی که تو کارخونه قطعاتو مونتاژ می‌کنن، با استفاده از RL حرکات خودشونو بهبود می‌دن و دقتو بالا می‌برن و مصرف انرژی رو کم می‌کنن.</li>
                <li><strong>بازی‌ها:</strong> از AlphaGo که تو بازی Go استاد شد گرفته تا ایجنتای RL که تو بازیای پیچیده ویدیویی مهارت پیدا کردن، RL پتانسیلشو برای حل مسائل سخت با یادگیری مستقیم از تجربه نشون داده.</li>
            </ul>
    
            <div class="box box-tip">
                <strong>یه فعالیت جالب:</strong> ه بازی پیدا کن که قوانینشو تو حین بازی یاد بگیری. چطوری تعادل بین امتحان کردن حرکات جدید (کاوش) و پایبند بودن به حرکاتی که می‌دونی جواب می‌ده (بهره‌برداری) برقرار می‌کنی؟
            </div>
        </section>
    </main>
    

    <footer class="social-footer">
        <a href="https://t.me/RL_Hub" target="_blank"><i class="fab fa-telegram"></i></a>
        <a href="https://github.com/The-RL-Hub" target="_blank"><i class="fab fa-github"></i></a>
        <a href="mailto:arshiyagharoony@gmail.com"><i class="fas fa-envelope"></i></a>
    </footer>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
    <script>
        hljs.highlightAll();
    </script>
    <script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
    
